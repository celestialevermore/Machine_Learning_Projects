{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae7d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    \n",
    "    #fit()메소드는 아무것도 학습하지 않음\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    #predict() 메소드는 단순히 Sex feature가 1이면 0, 그렇지 않으면 1로 예측함\n",
    "    # test용 feature 데이터가 들어올 것임\n",
    "    def predict(self,X):\n",
    "        pred=np.zeros((X.shape[0],1))\n",
    "        for i in range(X.shape[0]):\n",
    "            #남자이면 사망\n",
    "            if X['Sex'].iloc[i]==1:\n",
    "                pred[i]=0\n",
    "            #그렇지 않으면 생존\n",
    "            else:\n",
    "                pred[i]=1\n",
    "        return pred\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232f301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성을 제거하는 함수\n",
    "def drop_needless_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#레이블 인코딩을 수행하는 함수\n",
    "def format_features(df):\n",
    "    df['Cabin']=df['Cabin'].str[:1]\n",
    "    features=['Cabin','Sex','Embarked']\n",
    "    \n",
    "    for feature in features:\n",
    "        le=LabelEncoder()\n",
    "        le=le.fit(df[feature])\n",
    "        df[feature]=le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 위에서 만든 세 개의 모듈을 합쳐 Preprocessing 함수를 만든다.\n",
    "def transform_features(df):\n",
    "    df=fillna(df)\n",
    "    df=drop_needless_features(df)\n",
    "    df=format_features(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e3af519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는:0.7877\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터 / 테스트 데이터를 분할합니다.\n",
    "titanic_df = pd.read_csv('C:/Users/user/Jupyter_project/Practice/titanic/train.csv')\n",
    "\n",
    "\n",
    "#생존자컬럼만 떼놓고\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "#학습용 데이터셋에서는 생존자 컬럼을 삭제한다.\n",
    "X_titanic_df=titanic_df.drop('Survived',axis=1)\n",
    "#데이터 가공을 한다.\n",
    "X_titanic_df=transform_features(X_titanic_df)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_titanic_df,y_titanic_df,test_size=0.2,random_state=0)\n",
    "\n",
    "#위에서 생성한 Dummy Classifier를 이용하여, 학습/예측/평가를 수행합니다.\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train,y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "\n",
    "print('Dummy Classifier의 정확도는:{0:.4f}'.format(accuracy_score(y_test,mypredictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863992d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70626aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "### digits.data.shape: (1797, 64)\n",
      "[0 1 2 ... 8 9 8]\n",
      "### digits.target.shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "    \n",
    "    #입력값으로 들어오는 X 데이터셋의 크기만큼 모두 0값으로 만들어서 반환\n",
    "    def predict(self,X):\n",
    "        return np.zeros((len(X),1),dtype=bool)\n",
    "\n",
    "\n",
    "# 사이킷런의 내장 데이터 셋인 load_digits()를 이용하여 MNIST 데이터를 로딩합니다.\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits.data)\n",
    "print('### digits.data.shape:',digits.data.shape)\n",
    "print(digits.target)\n",
    "print('### digits.target.shape:',digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f209184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target==7\n",
    "\n",
    "type((digits.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fcb039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits번호가 7번이면 True, 이를 astype(int)로 1로 변환, 7번이 아니면, False이고 0으로 반환.\n",
    "y = (digits.target==7).astype(int)\n",
    "X_train,X_test,y_train,y_test=train_test_split(digits.data,y,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "248ac883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트셋 크기 : (450,)\n",
      "테스트셋 레이블 0 과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는 : 0.900\n"
     ]
    }
   ],
   "source": [
    "#불균형한 레이블 데이터 분포도 확인\n",
    "print('레이블 테스트셋 크기 :',y_test.shape)\n",
    "print('테스트셋 레이블 0 과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "# Dummy Classifier로 학습/예측/정확도 평가\n",
    "fakeclf=MyFakeClassifier()\n",
    "fakeclf.fit(X_train,y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는 : {:.3f}'.format(accuracy_score(y_test,fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a5fd2",
   "metadata": {},
   "source": [
    "### 정밀도(Precision)과 재현율(Recall)\n",
    "\n",
    "- MyFakeClassifier의 예측 결과로 정밀도와 재현율 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa4b8b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도: 0.0\n",
      "재현율: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score,recall_score\n",
    "\n",
    "print('정밀도:',precision_score(y_test,fakepred))\n",
    "print('재현율:',recall_score(y_test,fakepred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce71e9",
   "metadata": {},
   "source": [
    "오차행렬, 정확도, 정밀도, 재현율을 한꺼번에 계산하는 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1df5a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score,recall_score,confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "#정확도, 정밀도, 재현율을 한꺼번에!!\n",
    "def get_clf_eval(y_test,pred):\n",
    "    confusion = confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision=precision_score(y_test,pred)\n",
    "    recall=recall_score(y_test,pred)\n",
    "    \n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도 : {0:.4f} 정밀도 : {1:.4f} 재현율 : {2:.4f}'.format(accuracy,precision,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b374d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도 : 0.8492 정밀도 : 0.7742 재현율 : 0.7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할\n",
    "\n",
    "titanic_df = pd.read_csv('C:/Users/user/Jupyter_project/Practice/titanic/train.csv')\n",
    "\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df=titanic_df.drop('Survived',axis=1)\n",
    "X_titanic_df= transform_features(X_titanic_df)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_titanic_df,y_titanic_df,test_size=0.2,random_state=11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "\n",
    "#정확도, 정밀도, 재현율을 모두 측정하는 함수를 호출\n",
    "get_clf_eval(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac659a4c",
   "metadata": {},
   "source": [
    "#### Precision/Recall Trade-off\n",
    "\n",
    "- predict_proba() 메소드 확인 이진분류 즉 0일 때 확률이 얼마, 1일 때 확률이 얼마인지를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "396fc310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba()결과 Shape : (179, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 \n",
      ": [[0.46170212 0.53829788]\n",
      " [0.87864222 0.12135778]\n",
      " [0.87728507 0.12271493]]\n",
      "두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n",
      " [[0.46170212 0.53829788 1.        ]\n",
      " [0.87864222 0.12135778 0.        ]\n",
      " [0.87728507 0.12271493 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred = lr_clf.predict(X_test)\n",
    "print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:',pred_proba[:3])\n",
    "\n",
    "#예측 확률 array 와 예측 결과값 array를 concatenate 하여 예측 확률과 결과값을 한눈에 확인 \n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)],axis=1)\n",
    "print('두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n',pred_proba_result[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a12475",
   "metadata": {},
   "source": [
    "#### Binarizer 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1da94ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [[1,-1,2],\n",
    "      [2,0,0],\n",
    "    [0,1.1,1.2]]\n",
    "\n",
    "# Threshold 기준값보다 같거나 작으면, 0 크면 1을 반환\n",
    "binarizer= Binarizer(threshold=1.1)\n",
    "\n",
    "print(binarizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d090ba3",
   "metadata": {},
   "source": [
    "Binarizer와 pred_proba 함수를 이용하여 predict 함수를 흉내 내보도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbcecae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도 : 0.8492 정밀도 : 0.7742 재현율 : 0.7869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#Binarizer의 threshold 설정값, 분류 결정 임곗값임.\n",
    "custom_threshold = 0.5\n",
    "\n",
    "# predict_proba() 반환값의 두 번째 컬럼, 즉 Positive 클래스 컬럼 하나만 따로 추출하여 BInarizer를 적용\n",
    "\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test,custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6c2db2",
   "metadata": {},
   "source": [
    "#### 여러 개의 분류 결정 임곗값을 변경하면서 Binarizer를 이용하여 예측값 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac48cabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임곗값: 0.4\n",
      "오차 행렬\n",
      "[[99 19]\n",
      " [10 51]]\n",
      "정확도 : 0.8380 정밀도 : 0.7286 재현율 : 0.8361\n",
      "임곗값: 0.45\n",
      "오차 행렬\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "정확도 : 0.8492 정밀도 : 0.7656 재현율 : 0.8033\n",
      "임곗값: 0.5\n",
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도 : 0.8492 정밀도 : 0.7742 재현율 : 0.7869\n",
      "임곗값: 0.55\n",
      "오차 행렬\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "정확도 : 0.8659 정밀도 : 0.8364 재현율 : 0.7541\n",
      "임곗값: 0.6\n",
      "오차 행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도 : 0.8771 정밀도 : 0.8824 재현율 : 0.7377\n"
     ]
    }
   ],
   "source": [
    "# 테스트를 수행할 모든 임곗값을 리스트 객체로 저장.\n",
    "thresholds = [0.4,0.45,0.50,0.55,0.60]\n",
    "\n",
    "\n",
    "\n",
    "def get_eval_by_thresholds(y_test,pred_proba_c1,thresholds):\n",
    "    #thresholds list 객체 내의 값을 차례로 iteration 하면서 Evaluation 수행\n",
    "    \n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        \n",
    "        print('임곗값:',custom_threshold)\n",
    "        get_clf_eval(y_test,custom_predict)\n",
    "\n",
    "\n",
    "get_eval_by_thresholds(y_test,pred_proba[:,1].reshape(-1,1),thresholds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943c1336",
   "metadata": {},
   "source": [
    "#### precision_recall_curve() 를 이용하여 임곗값에 따른 정밀도-재현율 값 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b03de0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반환된 분류 결정 임곗값 배열의 Shape: (143,)\n",
      "반환된 precisions 배열의 Shape: (144,)\n",
      "반환된 recalls 배열의 Shape: (144,)\n",
      "thresholds 5 samples: [0.10392303 0.10392523 0.10394993 0.10734518 0.10890452]\n",
      "precisions 5 samples: [0.38853503 0.38461538 0.38709677 0.38961039 0.38562092]\n",
      "recalls 5 samples: [1.         0.98360656 0.98360656 0.98360656 0.96721311]\n",
      "샘플 추출을 위한 임곗값 배열의 index 10개: [  0  15  30  45  60  75  90 105 120 135]\n",
      "샘플용 10개의 임곗값:  [0.1  0.12 0.14 0.19 0.28 0.4  0.57 0.67 0.82 0.95]\n",
      "샘플 임곗값 별 정밀도 : [0.389 0.44  0.466 0.539 0.647 0.729 0.836 0.949 0.958 1.   ]\n",
      "샘플 임곗값 별 재현율 : [1.    0.967 0.902 0.902 0.902 0.836 0.754 0.607 0.377 0.148]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "#레이블 값이 1일 때의 예측 확률을 추출\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "#실제값 데이터 셋과 레이블 값이 1일 때의 예측 확률을 precision_recall_curve 인자로 입력합니다.\n",
    "\n",
    "precisions, recalls,thresholds = precision_recall_curve(y_test,pred_proba_class1)\n",
    "print('반환된 분류 결정 임곗값 배열의 Shape:',thresholds.shape)\n",
    "print('반환된 precisions 배열의 Shape:',precisions.shape)\n",
    "print('반환된 recalls 배열의 Shape:',recalls.shape)\n",
    "\n",
    "print(\"thresholds 5 samples:\",thresholds[:5])\n",
    "print(\"precisions 5 samples:\",precisions[:5])\n",
    "print(\"recalls 5 samples:\",recalls[:5])\n",
    "\n",
    "#반환된 임곗값 배열 로우가 총 147건이므로 샘플로 10건만 추출하되, 임곗값을 15 Step으로 추출\n",
    "thr_index = np.arange(0,thresholds.shape[0],15)\n",
    "\n",
    "print('샘플 추출을 위한 임곗값 배열의 index 10개:',thr_index)\n",
    "print('샘플용 10개의 임곗값: ',np.round(thresholds[thr_index],2))\n",
    "\n",
    "\n",
    "#15 step 단위로 추출된 임곗값에 따른 정밀도와 재현율 값\n",
    "print('샘플 임곗값 별 정밀도 :',np.round(precisions[thr_index],3))\n",
    "print('샘플 임곗값 별 재현율 :',np.round(recalls[thr_index],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc648ca5",
   "metadata": {},
   "source": [
    "#### 3.4 f1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4988e4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 스코어 : 0.7805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test,pred)\n",
    "\n",
    "print('F1 스코어 : {0:.4f}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "458df9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임곗값: 0.4\n",
      "오차 행렬\n",
      "[[99 19]\n",
      " [10 51]]\n",
      "정확도 : 0.8380 정밀도 : 0.7286 재현율 : 0.8361\n",
      "임곗값: 0.45\n",
      "오차 행렬\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "정확도 : 0.8492 정밀도 : 0.7656 재현율 : 0.8033\n",
      "임곗값: 0.5\n",
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도 : 0.8492 정밀도 : 0.7742 재현율 : 0.7869\n",
      "임곗값: 0.55\n",
      "오차 행렬\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "정확도 : 0.8659 정밀도 : 0.8364 재현율 : 0.7541\n",
      "임곗값: 0.6\n",
      "오차 행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도 : 0.8771 정밀도 : 0.8824 재현율 : 0.7377\n"
     ]
    }
   ],
   "source": [
    "def get_lf_eval(y_test,pred):\n",
    "    confusion = confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred)\n",
    "    recall = recall_score(y_test,pred)\n",
    "    \n",
    "    #F1 Score추가\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    \n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    \n",
    "    # f1 score print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},F1:{3:.4f}'.format(accuracy,precision,recall,f1))\n",
    "\n",
    "\n",
    "thresholds=[0.4,0.45,0.50,0.55,0.60]\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "\n",
    "get_eval_by_thresholds(y_test,pred_proba[:,1].reshape(-1,1),thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1fbe22",
   "metadata": {},
   "source": [
    "#### 3.5 ROC Curve와 AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b45a259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 추출을 위한 임곗값 배열의 index 10개: [ 0  5 10 15 20 25 30 35 40 45 50]\n",
      "샘플용 10개의 임곗값: [1.97 0.75 0.63 0.59 0.49 0.4  0.31 0.15 0.12 0.11 0.1 ]\n",
      "샘플 임곗값별 FPR : [0.    0.017 0.034 0.059 0.127 0.161 0.237 0.483 0.61  0.703 0.814]\n",
      "샘플 임곗값별 TPR : [0.    0.475 0.672 0.754 0.787 0.852 0.885 0.902 0.934 0.967 0.984]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#레이블 값이 1일 때의 예측 확률을 추출\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "FPRS, TPRS, thresholds = roc_curve(y_test,pred_proba_class1)\n",
    "#변환은 임곗값 배열 로우가 47건이므로 샘플로 10건만 추출하되, 임곗값을 5 Step으로\n",
    "\n",
    "thr_index = np.arange(0,thresholds.shape[0],5)\n",
    "\n",
    "print('샘플 추출을 위한 임곗값 배열의 index 10개:',thr_index)\n",
    "print('샘플용 10개의 임곗값:',np.round(thresholds[thr_index],2))\n",
    "\n",
    "# 5 step 단위로 추출된 임곗값에 따른 FPR,TPR 값\n",
    "\n",
    "print('샘플 임곗값별 FPR :',np.round(FPRS[thr_index],3))\n",
    "print('샘플 임곗값별 TPR :',np.round(TPRS[thr_index],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15276a5",
   "metadata": {},
   "source": [
    "해당 ROC Curve를 그려보면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b5587a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "def roc_curve_plot(y_test,pred_proba_c1):\n",
    "    #임곗값에 따른 FPR, TPR 값을 변환 받음\n",
    "    \n",
    "    FPRS,TPRS,thresholds = roc_curve(y_test,pred_proba_c1)\n",
    "    \n",
    "    #ROC Curve를 plot 곡선으로 그림\n",
    "    plt.plot(FPRS,TPRS,label='ROC')\n",
    "    \n",
    "    #가운데 대각선 직선을 그린다. \n",
    "    plt.plot([0,1],[0,1],'k--',label='Random')\n",
    "    \n",
    "    #FPR X축의 SCale을 0.1 단위로 변경, X,Y 축명 설정\n",
    "    \n",
    "    start,end=plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start,end,0.1),2))\n",
    "    plt.xlim(0,1);plt.ylim(0,1)\n",
    "    plt.xlabel('FPR( 1 - Sensitiveity)');plt.ylabel('TPR(Recall)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "roc_curve_plot(y_test,lr_clf.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f09f2852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 값: 0.9024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "### 아래는 roc_auc_score()의 인자를 잘못 입력한 것입니다.\n",
    "## 종전에는 roc_auc_score(y_test,pred)로 예측 타겟을 입력하였음\n",
    "### roc_auc_score(y_test,y_score)는 predict_proba()로 호출된 예측 확률 ndarray 가운데에서 Positive열에 해당하는 ndarray\n",
    "\n",
    "#pred= lr_clf.predict(X_test)\n",
    "#roc_score = roc_auc_score(y_test,pred)\n",
    "\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:,1]\n",
    "#1이 positive에 해당하는 열임 0은 구라\n",
    "roc_score = roc_auc_score(y_test,pred_proba)\n",
    "print('ROC AUC 값: {0:.4f}'.format(roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73eac61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test,pred=None,pred_proba=None):\n",
    "    #오차행렬\n",
    "    confusion = confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred)\n",
    "    recall = recall_score(y_test,pred)\n",
    "    \n",
    "    f1 = f1_score(y_test,pred)\n",
    "    \n",
    "    #ROC-AUC 추가\n",
    "    roc_auc = roc_auc_score(y_test,pred_proba)\n",
    "    \n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, \\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9749aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
